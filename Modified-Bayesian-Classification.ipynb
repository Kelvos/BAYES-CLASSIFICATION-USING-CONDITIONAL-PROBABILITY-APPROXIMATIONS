{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e3e8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import Counter\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "import csv\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings as warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb046ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TimeError(Exception):\n",
    "    \"\"\"Custom exception class for timer\"\"\"\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start a new timer\"\"\"\n",
    "        if self._start_time is not None:\n",
    "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
    "\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "\n",
    "        elapsed_time = time.perf_counter() - self._start_time\n",
    "        self._start_time = None\n",
    "        return(elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "682919e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_file):\n",
    "    df = pd.read_csv('{}'.format(data_file),header=None)\n",
    "\n",
    "    \n",
    "    #UCI has ? as missing data\n",
    "    df = df[~df.eq('?').any(1)]\n",
    "    df.dropna(axis = 1, how ='all', inplace = True)\n",
    "    df.dropna(axis = 0, how ='all', inplace = True)\n",
    "    df.to_csv('cleaned_frame.csv'.format(data_file),index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #reread for appropriate column dtypes\n",
    "    df = pd.read_csv('cleaned_frame.csv',header=0)\n",
    "    result_summary[data_file][\"data_type\"]=Counter(df.dtypes.tolist())\n",
    "    \n",
    "    #convert Y to integer type\n",
    "    df[df.columns[-1]]=df[df.columns[-1]].astype('str')\n",
    "    df[df.columns[-1]]=df[df.columns[-1]].str.strip()\n",
    "    df[df.columns[-1]]=df[df.columns[-1]].astype('category')\n",
    "    df[df.columns[-1]]=df[df.columns[-1]].cat.codes\n",
    "    \n",
    "    #get the columns that needed to be label encoded\n",
    "    conversion_idx=[]\n",
    "\n",
    "    for idx,d_type in enumerate(df.dtypes.values):\n",
    "        if \"object\" == d_type:\n",
    "            conversion_idx.append(idx)\n",
    "\n",
    "    \n",
    "    \n",
    "    #clean categories of white space\n",
    "    for idx in conversion_idx:\n",
    "        df.iloc[:,idx]=df.iloc[:,idx].astype('str')\n",
    "        df.iloc[:,idx]=df.iloc[:,idx].str.strip()\n",
    "        df.iloc[:,idx]=df.iloc[:,idx].astype('category')\n",
    "    \n",
    "    #encode strings as numbers\n",
    "    for idx in conversion_idx:\n",
    "        labels = df.iloc[:,idx].astype('category').cat.categories.tolist()\n",
    "        replace_map_comp = {idx : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "        df.iloc[:,idx].replace(replace_map_comp[idx], inplace=True)\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27052169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "\n",
    "class MNBClassifier(ClassifierMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, kappa=20):\n",
    "        self.kappa = kappa\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        y_pred=[]\n",
    "        z = np.zeros((np.shape(self.classes_)[0],1 ))\n",
    "        for i in range(len(self.X_)):\n",
    "            z[int(self.y_[i])] += 1  \n",
    "\n",
    "        z = z/sum(z)\n",
    "            \n",
    "\n",
    "        \n",
    "        R = np.zeros((np.shape(self.X_)[1],1))\n",
    "        for k in range(0, np.shape(self.X_)[1]): \n",
    "            R[k] = np.amax(self.X_[:,k]) - np.amin(self.X_[:,k])\n",
    "        \n",
    "\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            v = np.zeros((np.shape(self.classes_)[0],1))\n",
    "            c = np.zeros((np.shape(self.classes_)[0],1))\n",
    "            p = np.zeros((np.shape(self.classes_)[0],1))\n",
    "            for j in range(len(self.X_)):\n",
    "                d=0\n",
    "                for k in range(0,np.shape(self.X_)[1]):\n",
    "                    d += ((X[i,k] - self.X_[j,k])/R[k])**2\n",
    "                v[int(self.y_[j])] += 1/((1 + math.sqrt(d))**self.kappa)\n",
    "                c[int(self.y_[j])] += 1\n",
    "            p = z*v/c\n",
    "\n",
    "            y_pred.append(np.argmax(p))\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083770fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def feature_selection(model,X,y,kf,num_CV):\n",
    "\n",
    "\n",
    "    important_features={}\n",
    "    for col in X.columns:\n",
    "        important_features[col]=0\n",
    "        \n",
    "    for train_index , test_index in kf.split(X,y):\n",
    "        X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "        y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "        \n",
    "        model = model.fit(X_train, y_train)\n",
    "        r = permutation_importance(model, X_test, y_test,\n",
    "                           n_repeats=30,\n",
    "                           random_state=0,\n",
    "                                  scoring= 'accuracy')\n",
    "        imp_features=[]\n",
    "        for imp_idx,i in enumerate(r.importances_mean):\n",
    "            important_features[str(imp_idx)] += i\n",
    "\n",
    "\n",
    "    \n",
    "    sorted_features = {k: v for k, v in sorted(important_features.items(), key=lambda item: item[1],reverse = True)}\n",
    "    final_features=[]\n",
    "    highest_score = [0,0]\n",
    "    for k,v in sorted_features.items():\n",
    "    \n",
    "        if v>0:\n",
    "            final_features.append(int(k))\n",
    "    \n",
    "            X_feat_selection = X.iloc[:,final_features]\n",
    "\n",
    "\n",
    "            for train_index , test_index in kf.split(X_feat_selection,y):\n",
    "                if len(final_features)<2:\n",
    "                     X_train , X_test = X_feat_selection.iloc[train_index], X_feat_selection.iloc[test_index]\n",
    "                else:\n",
    "                    X_train , X_test = X_feat_selection.iloc[train_index,:], X_feat_selection.iloc[test_index,:]\n",
    "\n",
    "                y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "                y_pred_t = model.fit(X_train, y_train).predict(X_test)\n",
    "                highest_score[0] += (1-((y_test != y_pred_t).sum()/(X_test.shape[0])))/num_CV\n",
    "\n",
    "            if highest_score[0]>highest_score[1]:\n",
    "                highest_score[1]=highest_score[0]\n",
    "                highest_score[0]=0\n",
    "            else:\n",
    "                final_features.pop()\n",
    "                highest_score[0]=0\n",
    "\n",
    "    print(\"final features {}\".format(final_features))\n",
    "    return(final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e48bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iris.data.csv', 'Dry_Bean_Dataset.csv', 'BreastTissue.csv', 'Algerian_forest_fires_dataset_UPDATE_modified.csv', 'sobar-72.csv', 'credi_data.data.csv', 'heart.dat.csv', 'wine.data.csv', 'breast-cancer.data.csv', 'balance-scale.data2.csv', 'winequality-red.csv', 'tic-tac-toe.data.csv', 'australian.dat.csv', 'yeast.data.csv', 'Raisin_Dataset.csv', 'winequality-white.csv', 'data_banknote_authentication.csv', 'balance-scale.data.csv', 'abalone.data.csv', 'heart_failure_clinical_records_dataset.csv', 'bcdata.csv', 'glass.data.csv', 'leaf.data.csv']\n",
      "iris.data.csv\n",
      "final features [3, 2]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-70b5a30fe7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mnaive_bayes_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-70b5a30fe7ae>\u001b[0m in \u001b[0;36mnaive_bayes_analysis\u001b[0;34m(data_file, result_summary)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mparams_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'kappa'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         search_MNB = GridSearchCV(MNBClassifier(), param_grid=params_grid,\n\u001b[0m\u001b[1;32m     58\u001b[0m                                   n_jobs=-1,cv=kf,scoring='accuracy').fit(X, y)\n\u001b[1;32m     59\u001b[0m         \u001b[0mparams_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_neighbors'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rapids-core-0.17/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "def naive_bayes_analysis(data_file,result_summary={}):\n",
    "    \n",
    "    #set up data collection \n",
    "\n",
    "\n",
    "    result_summary[data_file]={}\n",
    "    result_summary[data_file][\"data_file\"]=data_file\n",
    "    result_summary[data_file][\"Gaussian\"]=0\n",
    "    result_summary[data_file][\"Laplacian\"]=0\n",
    "    result_summary[data_file][\"kNN\"]=0\n",
    "    result_summary[data_file][\"kNN_20\"]=0\n",
    "    result_summary[data_file][\"MNB_optimal\"]=0\n",
    "    result_summary[data_file][\"MNB_20\"] = 0\n",
    "    result_summary[data_file][\"MNB_60\"] = 0\n",
    "    result_summary[data_file][\"MNB_time\"]=0\n",
    "    result_summary[data_file][\"Laplace_time\"]=0\n",
    "\n",
    "\n",
    "    seed_iter = list(range(0,10,1))\n",
    "    for seed in seed_iter:\n",
    "    \n",
    "\n",
    "        num_CV= 10        \n",
    "        kf = KFold(num_CV,shuffle=True,random_state=random.randint(1, 100))\n",
    "        score_GNB=[]\n",
    "        score_MNB =[]\n",
    "        score_HBNB =[]\n",
    "        score_kNN = []\n",
    "        t = Timer()\n",
    "        k_length=100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df = load_data(data_file)    \n",
    "        result_summary[data_file][\"data_size\"]=df.shape\n",
    "\n",
    "        X = df[df.columns[0:len(df.columns)-1]]\n",
    "\n",
    "        y= df[df.columns[-1]]\n",
    " \n",
    "\n",
    "\n",
    "        gnb = GaussianNB()\n",
    "        final_features = feature_selection(gnb,X,y,kf,num_CV)\n",
    "        result_summary[data_file][\"selected_features\"]=final_features\n",
    "        X = X.iloc[:,final_features]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # determine hyperparameters\n",
    "        labels = y.unique()\n",
    "        params_grid={'kappa':range(0,100,1)}\n",
    "        search_MNB = GridSearchCV(MNBClassifier(), param_grid=params_grid,\n",
    "                                  n_jobs=-1,cv=kf,scoring='accuracy').fit(X, y)\n",
    "        params_grid={'n_neighbors':range(1,100,1)}\n",
    "        search_KNN = GridSearchCV(KNeighborsClassifier(), param_grid=params_grid,\n",
    "                                  n_jobs=-1,cv=kf,scoring='accuracy').fit(X, y)\n",
    "        kappa = search_MNB.best_params_['kappa']\n",
    "\n",
    "\n",
    "\n",
    "        MNB_n=\"MNB_\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for train_index , test_index in kf.split(X,y):\n",
    "            X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "            y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "\n",
    "\n",
    "\n",
    "            #KNN\n",
    "\n",
    "            neigh = KNeighborsClassifier(n_neighbors=search_KNN.best_params_['n_neighbors'])\n",
    "            y_kNN_pred = neigh.fit(X_train, y_train).predict(X_test)\n",
    "            score_kNN.append(1-((y_test != y_kNN_pred).sum()/(X_test.shape[0])))\n",
    "            result_summary[data_file][\"kNN\"]+=(1-((y_test != y_kNN_pred).sum()/(X_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "\n",
    "\n",
    "            #KNN_20\n",
    "\n",
    "            neigh = KNeighborsClassifier(20)\n",
    "            y_kNN_pred = neigh.fit(X_train, y_train).predict(X_test)\n",
    "            score_kNN.append(1-((y_test != y_kNN_pred).sum()/(X_test.shape[0])))\n",
    "            result_summary[data_file][\"kNN_20\"]+=(1-((y_test != y_kNN_pred).sum()/(X_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "\n",
    "\n",
    "            #Gaussian\n",
    "    #         print(\"Gaussian method\")\n",
    "\n",
    "            t.start()\n",
    "            gnb = GaussianNB()\n",
    "            y_GNB_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "            score_GNB.append(1-((y_test != y_GNB_pred).sum()/(X_test.shape[0])))\n",
    "            result_summary[data_file][\"Gaussian\"]+=(1-((y_test != y_GNB_pred).sum()/(X_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "            t.stop()\n",
    "\n",
    "    #       \n",
    "            #modified\n",
    "\n",
    "    #         for kappa in resolution:\n",
    "\n",
    "\n",
    "       \n",
    "            MNB = MNBClassifier(kappa)\n",
    "\n",
    "            y_MNB_pred = MNB.fit(X_train, y_train).predict(X_test)            \n",
    "            result_summary[data_file][\"MNB_optimal\"]+=(1-((y_test != y_MNB_pred).sum()/(X_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "\n",
    "\n",
    "            MNB = MNBClassifier(20)\n",
    "            y_MNB_pred = MNB.fit(X_train, y_train).predict(X_test)\n",
    "            result_summary[data_file][\"MNB_20\"]+=(1-((y_test != y_MNB_pred).sum()/(X_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "\n",
    "            MNB = MNBClassifier(60)\n",
    "            t.start()\n",
    "            y_MNB_pred = MNB.fit(X_train, y_train).predict(X_test)\n",
    "            result_summary[data_file][\"MNB_60\"]+=(1-((y_test != y_MNB_pred).sum()/(X_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "            result_summary[data_file][\"MNB_time\"]=t.stop()/num_CV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #Laplacian\n",
    "\n",
    "\n",
    "\n",
    "            prob={}\n",
    "            y_MNB = []\n",
    "            t.start()\n",
    "            Z={}\n",
    "            for label in labels:\n",
    "                Z[label] = (y_train.values == label).sum()/y.shape[0]\n",
    "        #     print(\"Z {}\".format(Z))\n",
    "\n",
    "\n",
    "            for i,row in X_test.iterrows():\n",
    "                row = row.tolist()\n",
    "                class_sample_size = 0\n",
    "                zero_freq=0\n",
    "\n",
    "                #create prob dict\n",
    "                for label in labels:\n",
    "                    prob[label] = 0\n",
    "\n",
    "                for k, col in enumerate(X_train.columns):\n",
    "                    #casting to avoid iloc str error\n",
    "                    col = int(col)\n",
    "                    hosein_estimate = 1\n",
    "                    v = 10\n",
    "                    class_sample_size={}\n",
    "                    x_col = X_train.iloc[:,k]\n",
    "\n",
    "\n",
    "                    occ_score={}\n",
    "                    for label in labels:\n",
    "                        occ_score[label] = 0\n",
    "                        class_sample_size[label] = x_col[y_train==label].shape[0]\n",
    "\n",
    "                    for label in labels:\n",
    "                        v = (x_col[y_train==label].values == row[k]).sum()\n",
    "\n",
    "                        if (v == 0):\n",
    "                            occ_score[label] = 1\n",
    "                        else:\n",
    "                            occ_score[label] = v + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    for label in labels:\n",
    "                        prob[label] += math.log(occ_score[label]/(class_sample_size[label]+len(x_col.unique())))\n",
    "\n",
    "\n",
    "                for label in labels:\n",
    "                    prob[label] += math.log(Z[label])\n",
    "\n",
    "\n",
    "\n",
    "                y_MNB.append(max(prob.items(), key=operator.itemgetter(1))[0])\n",
    "            score_MNB.append(1-((y_test != y_MNB).sum()/(X_test.shape[0])))\n",
    "            result_summary[data_file][\"Laplacian\"]+=(1-((y_test != y_MNB).sum()/(y_test.shape[0])))/(num_CV*len(seed_iter))\n",
    "            result_summary[data_file][\"Laplace_time\"]=t.stop()/num_CV\n",
    "\n",
    "\n",
    "\n",
    "    winner = [result_summary[data_file][\"Gaussian\"],\n",
    "              result_summary[data_file][\"Laplacian\"],\n",
    "              result_summary[data_file][\"kNN\"],\n",
    "              result_summary[data_file][\"MNB_optimal\"]]\n",
    "    \n",
    "    result_summary[data_file]['Winner'] = winner.index(max(winner))\n",
    "    print(result_summary[data_file]['Winner'])\n",
    "    print(result_summary[data_file])\n",
    "    return result_summary\n",
    "    \n",
    "\n",
    "\n",
    "result_summary={}\n",
    "location='datasets3'    \n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "files = [f for f in listdir(location) if isfile(join(location, f))]\n",
    "print(files)\n",
    "\n",
    "for data_file in files:  \n",
    "    print(data_file)\n",
    "    naive_bayes_analysis('{}/{}'.format(location,data_file),result_summary)\n",
    "\n",
    "\n",
    "\n",
    "keys=None\n",
    "for result in result_summary:\n",
    "    keys = result_summary[result].keys()\n",
    "\n",
    "    #rename these results as corr > 0.XX\n",
    "with open('results.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "    w = csv.DictWriter(f, keys)\n",
    "    w.writeheader()\n",
    "    for result in result_summary:\n",
    "        w.writerow(result_summary[result])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0078c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
